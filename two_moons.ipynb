{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"two_moons\"):\n",
    "    os.mkdir(\"two_moons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topaxa/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/topaxa/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bqlearn.corruptions import (\n",
    "    make_cluster_imbalance,\n",
    "    make_instance_dependent_label_noise,\n",
    "    noisy_leaves_probability,\n",
    ")\n",
    "from bqlearn.corruptions.noise_matrices import flip_noise_matrix\n",
    "from sklearn import clone\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "seed = 2\n",
    "\n",
    "names = [\n",
    "    \"Concept Drift\",\n",
    "    \"Per-Class Cluster Imbalance\",\n",
    "]\n",
    "corruptions = [\n",
    "    lambda X, y: (\n",
    "        X,\n",
    "        make_instance_dependent_label_noise(\n",
    "            noisy_leaves_probability(\n",
    "                X,\n",
    "                y,\n",
    "                noise_ratio=0.2,\n",
    "                purity=\"ascending\",\n",
    "                min_samples_leaf=40,\n",
    "                random_state=seed,\n",
    "            ),\n",
    "            y,\n",
    "            noise_matrix=\"permutation\",\n",
    "            random_state=seed,\n",
    "        ),\n",
    "    ),\n",
    "    lambda X, y: make_cluster_imbalance(\n",
    "        X,\n",
    "        y,\n",
    "        per_class_n_clusters=4,\n",
    "        majority_ratio=10,\n",
    "        imbalance_distribution=\"linear\",\n",
    "        random_state=seed,\n",
    "    ),\n",
    "]\n",
    "\n",
    "n_samples = 500\n",
    "n_classes = 2\n",
    "\n",
    "datasets = [\n",
    "    make_moons(n_samples=n_samples, noise=0.2, random_state=seed),\n",
    "]\n",
    "\n",
    "clf = SVC(kernel=\"poly\", degree=3, coef0=1.0, probability=True)\n",
    "\n",
    "\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    clean_clf = clone(clf).fit(X, y)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    h = 0.02\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z_clean = clean_clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z_clean = Z_clean.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4.5))\n",
    "    # Plot the input points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
    "\n",
    "    c = ax.contour(xx, yy, Z_clean, levels=0, colors=\"black\")\n",
    "    h, _ = c.legend_elements()\n",
    "    ax.legend([h[0]], [\"clean\"])\n",
    "\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(\"two_moons\", \"clean.pdf\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        format=\"pdf\",\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    # iterate over corruptions\n",
    "    for name, corruption in zip(names, corruptions):\n",
    "        fig, ax = plt.subplots(figsize=(4.5, 4.5))\n",
    "\n",
    "        X_corrupted, y_corrupted = corruption(np.copy(X), np.copy(y))\n",
    "\n",
    "        # Plot the corrupted data\n",
    "        ax.scatter(\n",
    "            X_corrupted[:, 0],\n",
    "            X_corrupted[:, 1],\n",
    "            c=y_corrupted,\n",
    "            edgecolors=\"k\",\n",
    "        )\n",
    "\n",
    "        drift_clf = clone(clf).fit(X_corrupted, y_corrupted)\n",
    "\n",
    "        Z_corrupt = drift_clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z_corrupt = Z_corrupt.reshape(xx.shape)\n",
    "\n",
    "        c2 = ax.contour(\n",
    "            xx, yy, Z_corrupt, levels=0, linestyles=\"dashed\", colors=\"black\"\n",
    "        )\n",
    "        h2, _ = c2.legend_elements()\n",
    "        ax.legend([h2[0]], [\"corrupt\"])\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(\"two_moons\", name.replace(\" \", \"-\").lower() + \".pdf\"),\n",
    "            bbox_inches=\"tight\",\n",
    "            format=\"pdf\",\n",
    "        )\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topaxa/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/topaxa/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/topaxa/.local/lib/python3.8/site-packages/bqlearn/kdr/_kmm.py:267: UserWarning: Computed `batch_size` is less than 1 or larger than\n",
      "                the number of untrusted samples for this class.\n",
      "                It is going to be clipped.\n",
      "  warnings.warn(\"\"\"Computed `batch_size` is less than 1 or larger than\n",
      "/home/topaxa/.local/lib/python3.8/site-packages/bqlearn/kdr/_kmm.py:267: UserWarning: Computed `batch_size` is less than 1 or larger than\n",
      "                the number of untrusted samples for this class.\n",
      "                It is going to be clipped.\n",
      "  warnings.warn(\"\"\"Computed `batch_size` is less than 1 or larger than\n",
      "/home/topaxa/.local/lib/python3.8/site-packages/matplotlib/collections.py:963: RuntimeWarning: invalid value encountered in sqrt\n",
      "  scale = np.sqrt(self._sizes) * dpi / 72.0 * self._factor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x324 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bqlearn.corruptions import (\n",
    "    make_cluster_imbalance,\n",
    "    make_instance_dependent_label_noise,\n",
    "    make_label_noise,\n",
    "    noisy_leaves_probability,\n",
    ")\n",
    "from bqlearn.corruptions.noise_matrices import flip_noise_matrix\n",
    "from bqlearn.irbl import IRBL\n",
    "from bqlearn.irlnl import IRLNL\n",
    "from bqlearn.kdr import KKMM, KPDR\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import clone\n",
    "from sklearn.calibration import CalibratedClassifierCV, LabelEncoder\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from covariate import IRBL2, PDR\n",
    "\n",
    "seed = 2\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "names = [\"IRBL\", \"IRBL2\", \"KPDR\", \"PDR\", \"KKMM\"]\n",
    "classifiers = [\n",
    "    IRBL(clf, clf),\n",
    "    IRBL2(clf, clf, clf),\n",
    "    KPDR(clf, clf, method=\"probabilities\", n_jobs=-1),\n",
    "    PDR(clf, clf, method=\"probabilities\"),\n",
    "    KKMM(clf, batch_size=1000, n_jobs=-1),\n",
    "]\n",
    "\n",
    "n_samples = 1000\n",
    "n_classes = 2\n",
    "\n",
    "datasets = [\n",
    "    make_moons(n_samples=n_samples, noise=0.2, random_state=seed),\n",
    "]\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(4.5 * (len(classifiers) + 1), 4.5 * len(datasets)))\n",
    "\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    h = 0.02\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    trusted, untrusted = next(\n",
    "        StratifiedShuffleSplit(train_size=0.05, random_state=seed).split(X, y)\n",
    "    )\n",
    "    sample_quality = np.ones_like(y)\n",
    "    sample_quality[untrusted] = 0\n",
    "\n",
    "    _, _, subsampled = make_cluster_imbalance(\n",
    "        X,\n",
    "        y,\n",
    "        range(n_samples),\n",
    "        per_class_n_clusters=4,\n",
    "        majority_ratio=10,\n",
    "        imbalance_distribution=\"linear\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    y[untrusted] = make_instance_dependent_label_noise(\n",
    "        noisy_leaves_probability(\n",
    "            X,\n",
    "            y,\n",
    "            noise_ratio=0.3,\n",
    "            purity=\"ascending\",\n",
    "            min_samples_leaf=40,\n",
    "            random_state=seed,\n",
    "        )[untrusted],\n",
    "        y[untrusted],\n",
    "        noise_matrix=\"permutation\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    selected = np.hstack([trusted, subsampled])\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    cm_dark = ListedColormap([\"#FF8000\", \"#8000FF\"])\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4.5))\n",
    "    # Plot the untrusted points\n",
    "    ax.scatter(\n",
    "        X[subsampled, 0],\n",
    "        X[subsampled, 1],\n",
    "        c=y[subsampled],\n",
    "        edgecolors=\"k\",\n",
    "        alpha=0.4,\n",
    "    )\n",
    "    # Plot the trusted points\n",
    "    ax.scatter(X[trusted, 0], X[trusted, 1], c=y[trusted], edgecolors=\"k\", marker=\"s\")\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    plt.savefig(\n",
    "        os.path.join(\"two_moons\", \"total.pdf\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        format=\"pdf\",\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        fig, ax = plt.subplots(figsize=(4.5, 4.5))\n",
    "\n",
    "        clf.fit(\n",
    "            X[selected],\n",
    "            y[selected],\n",
    "            sample_quality=sample_quality[selected],\n",
    "        )\n",
    "\n",
    "        s = clf.sample_weight_\n",
    "\n",
    "        s_corrupted = np.copy(s[len(trusted) :])\n",
    "        s_corrupted /= s_corrupted.sum()\n",
    "        c_corrupted = np.copy(y[subsampled])\n",
    "\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            X[subsampled, 0],\n",
    "            X[subsampled, 1],\n",
    "            c=c_corrupted,\n",
    "            s=20 * len(s_corrupted) * s_corrupted,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.4,\n",
    "        )\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(\n",
    "            X[trusted, 0],\n",
    "            X[trusted, 1],\n",
    "            c=y[trusted],\n",
    "            marker=\"s\",\n",
    "            edgecolors=\"k\",\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(\"two_moons\", name.replace(\" \", \"-\").lower() + \".pdf\"),\n",
    "            bbox_inches=\"tight\",\n",
    "            format=\"pdf\",\n",
    "        )\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
